# 生成式人工智能导论

## （延申）了解大语言模型

ChatGPT：G——Generative生成，P——Pre-trained预训练，T——Transformer。google bard、anthropic claude等等也是类似的技术。

**ChatGPT的运作原理-文字接龙**，做文字接龙的模型就是语言模型。GPT的输出是给每一个可以接的符号一个几率，然后按照这个几率分布掷色子，掷到哪一个符号就输出哪一个符号，这就是为什么gpt同样的问题每次产生的答案可以不一样。**这些符号就叫做Token**。每一个语言模型所定义的token不一样，token是开发者设定好的，是在做文字接龙的时候可以选择的符号。比如gpt要输出unkillable这个词汇，就需要做三次文字接龙：un+kill+able。因为英语单词无法被穷举，所以英文的token不是一个单词，token必须可以被穷举，这样才能给每一个token一个几率。gpt的中文中一个方块字往往是好几个token（其他语言模型也有将一个字设为一个token的）。

<img src="/assets/post3/gpt原理.png" alt="gpt原理" width="300">
<img src="/assets/post3/gpt输出.png" alt="gpt输出" width="300">

**为何GPT要掷色子而不直接选择几率最大的符号？**
因为根据论文：https://arxiv.org/abs/1904.09751。
如果每次都选择几率最大的符号，模型就很容易疯狂跳帧，不停的loop输出一样的语句，而每次掷色子则可以看到自然的回答。

**正因为GPT的运作原理是文字接龙，所以GPT的输出有时候是瞎编**。GPT并不在意答案的正确与否，他只想接出一串合理又连贯的句子，比如我写毕业论文时曾试着让GPT找参考文献，结果文献的标题和地址都是瞎编的。

GPT在输出时过去所问问的问题、同一则对话的输出以及相关的资料都会作为文字接龙的一部分，**所以GPT可以相关联的回答**。如今GPT做文字接龙的长度可以长达到300页PDF文档的份量。

**语言模型如何学习文字接龙？**
任何一段话都可以是语言模型的教材。

<img src="/assets/post3/文字接龙学习方式.png" alt="文字接龙学习方式" width="400">

**输入句子是如何产生分布几率的呢？**
背后的原因令人暖心（非常复杂），简单地说今天语言模型的背后是一个巨大的类神经网络，类神经网络有非常多的类型，今天所用的就是transformer（gpt中t的缩写）。可以将类神经网络想象成一个函数，这个函数是输入一个不完整句子，输出一个几率分布。transformer里非常复杂的函数，实质上是一系列的矩阵乘法，**在学了机器学习以后可以更加了解**。

<img src="/assets/post3/类神经网络的参数.png" alt="文字接龙学习方式" width="400">

**类神经网络的具体形式，参数如何被找出，详情可见机器学习的课程**

早在18年openAI就发布了第一代GPT，第一代GPT就是个语言模型，语言模型透过大量的文字资料来学习做文字接龙。GPT-1没有掀起水花，因为他不是一个特别巨大的模型，只有117M的参数（在2018年不算大的类神经网络），只用了1GB的文字资料学习（也不是特别大的量）。而GPT-2有1542M的参数量，读的资料有40GB（在2019年算最大的模型）。openAI在gpt-2的论文中就展现出了将GPT打造成通用语言模型的野心。2020年，GPT-3的参数量有175B，读过的资料量有580GB（相当于阅读哈利波特全集30万遍，远超正常人类一生的阅读量），GPT-3最让人震惊的地方是他会写程序。

<img src="/assets/post3/参数量与资料量.png" alt="参数量与资料量" width="400">

**GPT-3为什么会写程序？**
因为语言模型是通过网络上大量的资料来做文字接龙，包括从GITHUB上爬到的大量代码。虽然GPT-3的模型非常大，但是他的正确率也不怎么样，只有50%左右，以至于当时许多人觉得openAI走错了方向。

**GPT-3为何差强人意？**
因为GPT-3是在网络上乱爬资料来学，并不知道如何回答人类的问题。

后来，**openAI进入了下一个阶段**，要有人类告诉人工智能我们想要什么答案。具体的说就是在回答输入的问题时，要将正确答案的几率分布调高，而错误答案的几率分布调低。**引入人类来教人工智能的学习，告诉人工智能什么是正确答案，这种学习方式称为督导式学习**。**人工智能在网络上爬到什么资料都拿来学习，没有老师的引导，这种方式称为自导式学习**。**督导式学习是真正的训练，自导式学习是预训练（GPT中P的缩写）**。预训练是非常关键的技术，是今天这些人工智能成功的背后的关键。今天的GPT又叫做基石模型，因为可以让基石模型做持续的学习，把他做一些微调，让他真正为人类服务。**把GPT经过微调经过持续的学习变成ChatGPT的过程，称为fine tune**。做一些微调以后，GPT模型本身的变化也许并不大，但能力却有相当大的增强。

<img src="/assets/post3/基石模型.png" alt="基石模型" width="400">

有督导式学习，小模型也有机会胜过大模型。预训练非常重要，有了预训练之后，督导式学习就不需要大量资料。在多种语言上做预训练以后，只要教某一个语言的某一个任务，模型能自动学会其他语言的同样任务。督导式学习是画龙点睛。

**除了督导式学习，模型还可以通过增强式学习来强化他的能力**。在增强式学习中，人类老师不再提供答案，而是提供回馈告诉模型什么样的答案是好的，什么样的答案是不好的。在督导式学习里人类要提供完整的正确答案，这样很花人类力气，而增强式学习每个人都可以做，当模型输出答案时，我们可以提供回馈，模型会根据提供的回馈进行学习。**增强式学习的内容可以参见增强式学习的课程**。

<img src="/assets/post3/增强式学习.png" alt="增强式学习" width="400">

**增强式学习的基本概念是，当模型生成两个答案时，会把我们觉得好的答案提高概率，把我们觉得不好的答案降低概率**。所以，顺序是先做预训练，再做督导式学习，最后做增强式学习。模型要有一定的能力才能进入增强式学习的环节。 

**督导式学习加增强式学习今天有一个术语来称呼这个过程——Alignment（对齐）**。模型学习的过程就是对齐人类的需求。

此时语言模型已经非常强了，下一阶段就到人类努力，激发语言模型的更大潜力。如何使模型发挥更大的能力：**1.将需求讲清楚；2.提供资讯给GPT；3.提供范例给GPT；4.鼓励GPT想一想**。

<img src="/assets/post3/方法1.png" alt="方法1" width="300">
<img src="/assets/post3/方法2.png" alt="方法2" width="300">
<img src="/assets/post3/方法3.png" alt="方法3" width="300">
<img src="/assets/post3/方法4.png" alt="方法4" width="300">

**5.问问题时，使用一些神奇咒语能使GPT的输出更准确**。如何找出神奇咒语呢？除了自己思考，也可以用AI来找，也就是用增强式学习的方式找神奇咒语，可以参考这篇论文：https://arxiv.org/abs/2309.03409。

<img src="/assets/post3/方法5.png" alt="方法5" width="400">

**6.可以上传档案**。

**7.GTP可以使用其他工具**，比如使用ML Paper Reader工具来搜索文献，GTP会将需求传送给ML Paper Reader，而ML Paper Reader就不是以文字接龙而是通过搜寻资料库的方式得出结果，这样会使答案更贴近你的需求。如果想知道ChatGPT是如何学会使用其他工具的，可以参考这个视频：https://youtu.be/ZID220t_Mpl?feature=shared。

<img src="/assets/post3/方法7.png" alt="方法7" width="400">

**8.拆解任务**。比如想让GPT写长篇小说，可以将写长篇小说这个任务拆解成许多简单的小任务。可以参考这篇论文：https://arxiv.org/abs/2210.06774。

<img src="/assets/post3/方法8.png" alt="方法8" width="400">

**9.可以让GPT自主进行规划**，如果任务过于复杂人类不知道如何拆解，可以让GPT把复杂的任务拆解成简单的任务，再对简单的任务逐个击破。AutoGPT、AgentGPT、BabyAGI、Godmode都可以将大任务拆解成小任务，再将小任务分开执行。

<img src="/assets/post3/方法9.png" alt="方法9" width="400">

**10.GPT也会反省**，可以让GPT检查上面的答案，如果答案错误，GPT会反省并改正（GPT-4以后的版本才有反省的能力）。事实上，用AI可以自我反省的能力，有办法去强化现有AI的能力，可以参考这篇很知名的论文（cloud用的技术）：https://arxiv.org/abs/2212.08073。
也可以让两个语言模型彼此挑战对方的观点，可以参考这篇论文：https://arxiv.org/abs/2303.17071。

**11.让语言模型与真实环境互动**，将外部咨询以图像的形式输入给GPT，将GPT输出的结果转译成可以执行的动作，比如转译给机械手臂，那么大语言模型就可以通过机械手臂去影响真实环境。可以参考这篇论文：https://arxiv.org/abs/2201.07207。

**想要了解更多与生成式人工智能有关的技术，可以订阅油管李宏毅的频道**。

编辑于2025年8月20日








