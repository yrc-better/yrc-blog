# 生成式人工智能导论

## 4训练不了人工智能，你可以训练你自己

**3.将复杂任务拆解成简单任务**，然后逐个击破。比如让AI写一个报告，可以先让AI写一个大纲，然后大纲里的每一个章节再分开撰写。为了防止前言不搭后语，可以令AI将过去已经写的内容整理成摘要，再根据过去的摘要来写新的段落。

<img src="/assets/post5/拆解.png" alt="拆解" width="600">

**为什么叫模型Chain of Thought或解释会有用**？
这其实也是一种拆解任务。比如AI解数学题，让他写出答案详细的计算过程，这就是把解题拆解成了两步，第一步AI先写出计算式，第二步AI再用计算式来计算结果。不过GPT3.5以后的模型解数学题都会预先列式了。

<img src="/assets/post5/先列式.png" alt="先列式" width="600">

**让语言模型检查自己的错误**，也可以使回答更准确。比如，AI写一篇文章，可以让他检查自己的语句是否有语法错误，并给出更正。也有很多问题是得到答案难，但验证答案是否正确很容易。**反省的过程没有模型被训练，模型的函数与参数都是固定的，所以下次再问同样的问题，AI还是有可能犯同样的错误**（在没有记忆的情况下）。

<img src="/assets/post5/检查错误.png" alt="检查错误" width="600">

**为什么同一个问题每次答案都不同？**
因为语言模型答题是在做文字接龙，后面接的每一个符号都有自己的几率（每输出一个符号都会新产生一个几率分布），而AI会通过掷色子决定下一步的走向。所以，每一次回答同样的问题，都有可能掷出不同的符号。

<img src="/assets/post5/掷色子.png" alt="掷色子" width="600">

**所以可以让AI多次做同一个问题**，把最常出现的答案当作是正确答案。

<img src="/assets/post5/多次.png" alt="多次" width="600">

**可以打一套组合拳，把拆解任务、多次回答、检查答案组合使用（Tree of Thoughts,ToT）**。

<img src="/assets/post5/组合拳.png" alt="组合拳" width="600">

**4.语言模型可以使用工具来强化自己的能力**。语言模型可能也有不擅长的事情，但也可以像人类一样通过使用额外的工具（插件）强化自己的能力。虽然我的GPT好像没有开放插件这个功能，GPT说逐步开放。比如说RAG方法，就是在问语言模型专业问题时，模型先去网络上搜索相关的资讯或资料库，再把额外的资讯传送给语言模型，语言模型就能更容易做出更精准的回答。但是也要注意，这也没有训练模型，模型的参数和函数都没有任何改变。GPT写程序也是使用了工具（Program of Thoughts,PoT）。文字生图也是使用了工具，调用了文字生图的AI（DALL-E）。

<img src="/assets/post5/RAG.png" alt="RAG" width="600">

<img src="/assets/post5/PoT.png" alt="PoT" width="600">

**语言模型如何使用工具？**
语言模型只会做一件事——文字接龙，所以当语言模型使用工具时也是以文字接龙的方式。文字接龙时可以接一些特殊的符号，这些符号就意味着呼叫工具，当工具使用完后，又会接一些特殊的符号，这些符号就代表着使用工具结束。而特殊的符号就是使用工具的指令。

<img src="/assets/post5/使用工具.png" alt="使用工具" width="600">

**怎么强化语言模型使用工具的能力？**
可以参考这篇paper：https://arxiv.org/abs/2402.04253

## 作业：用API快速搭建自己的应用

**什么是API？**
API：Application Programming Interface，应用程序编程接口。是使用程序的方式来调用GPT的方法。

本次作业的任务：

<img src="/assets/post5/作业任务.png" alt="作业任务" width="600">

作业colab链接：https://colab.research.google.com/drive/15jh4v_TBPsTyIBhi0Fz46gEkjvhzGaBR?usp=sharing&utm_source=chatgpt.com。

bug点：有环境中安装包版本太旧和兼容性的问题，代码改了几次都没有运行成功。有运行成功的同学可以留言告诉一下我（虽然我的博客目前还没有留言功能）。

<img src="/assets/post5/bug点.png" alt="bug点" width="600">

## 5训练不了模型，你可以训练你自己

**5.模型合作：让合适的模型做合适的事。**
让一个模型来判断任务更适合哪个模型，然后再把任务交给适合的模型来做，使用更低廉的成本来获得更好的效果。

<img src="/assets/post5/模型合作.png" alt="模型合作" width="600">

**模型合作：让模型彼此讨论。**
假设有两个模型A与B，模型A得出一个答案，模型B根据模型A的答案得到一个新的答案，模型A再根据模型B的答案得到一个更新的答案。

<img src="/assets/post5/模型彼此讨论.png" alt="模型彼此讨论" width="600">

让模型彼此讨论的效果非常显著，下图纵轴是模型推翻原答案的几率，横轴是两模型互动的次数。除此之外，有更多的模型参与讨论，效果就越好。

<img src="/assets/post5/彼此讨论效果.png" alt="彼此讨论效果" width="600">

<img src="/assets/post5/多个模型讨论.png" alt="多个模型讨论" width="600">

**模型讨论的形式也多种多样**。可以A，B，C三个模型相互讨论，共享答案；可以A当B，C的老板，A分别与B，C讨论；也可以A把答案给C，C把答案给B，B再把答案给A，这样循环；还可以B跟C相互讨论，由A来做裁判，评判结果。不同的任务适合的方式不一样。

<img src="/assets/post5/多种讨论方式.png" alt="多种讨论方式" width="600">

**讨论如何结束？**
可以有一个裁判模型，来判断两个模型的讨论有没有达成共识，如果没有达成共识，讨论就继续下去。因为语言模型在遭到质疑时非常容易退缩，所以要下一些合适的prompt鼓励模型反对对方的观点。

<img src="/assets/post5/反对prompt.png" alt="反对prompt" width="600">

**讨论时可以引入不同能力的语言模型，扮演不同的角色。**
甚至可以优化团队，让扮演不同角色的模型彼此打分，分数低的模型被淘汰。

<img src="/assets/post5/模型团队.png" alt="模型团队" width="600">

<img src="/assets/post5/优化团队.png" alt="优化团队" width="600">

**想体验领导一个AI团队现在也有一些开源的项目：MetaGPT、ChatDev**。感觉很有意思。**也许在未来，不需要打造全能的模型，大语言模型也可以分工，不同人类团队专注于打造专业领域的语言模型，不同专业领域的语言模型组成一个团队，组成一个公司**。

<img src="/assets/post5/模型团.png" alt="模型团" width="600">

**语言模型可以组成一个公司，就可以组成一个社群。**
下图中的论文就做了一个由语言模型组成的小镇，所有村民都是语言模型。

<img src="/assets/post5/模型社群.png" alt="模型社群" width="600">


编辑于2025年8月22日

